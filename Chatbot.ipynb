{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmDKCh29yxs7",
        "outputId": "b0d341c2-a0b8-47ba-daf3-bb69064890f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to cloud.r-project.org (18.154.101.112)] [Connecte\r                                                                                                    \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Waiting for headers] [Waiting for headers] [Co\r                                                                                                    \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: flask_tunnel in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (from flask_tunnel) (7.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 selenium transformers flask-ngrok --quiet\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver --quiet\n",
        "!pip install flask flask_tunnel transformers\n",
        "!pip install lxml[html_clean] --quiet\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests_html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCYTHTNkU-Px",
        "outputId": "8bd796df-ed56-4b86-994d-6c2662965e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests_html in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests_html) (2.32.3)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.10/dist-packages (from requests_html) (2.0.1)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.10/dist-packages (from requests_html) (2.0.3)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.10/dist-packages (from requests_html) (1.20.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (from requests_html) (0.0.2)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.10/dist-packages (from requests_html) (2.2.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.10/dist-packages (from requests_html) (2.0.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (2024.12.14)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (8.5.0)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (11.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.67.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.26.20)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (10.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests_html) (4.12.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests_html) (5.3.0)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests_html) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->requests_html) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests_html) (3.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests_html) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests_html) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio requests-html beautifulsoup4 sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKoS2cLxjnKm",
        "outputId": "0ba55f51-7b60-4408-8567-05d4f02d79a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.32.3)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.0.1)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.0.3)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.10/dist-packages (from requests-html) (1.20.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (from requests-html) (0.0.2)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.2.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (2024.12.14)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.5.0)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (11.1.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.26.20)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (10.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.1)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (5.3.0)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.10)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromedriver_autoinstaller"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-PMGITi1OGd",
        "outputId": "127c2549-93af-4c57-9eae-7b8924b0d151"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromedriver_autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver_autoinstaller) (24.2)\n",
            "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: chromedriver_autoinstaller\n",
            "Successfully installed chromedriver_autoinstaller-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Initialize the SentenceTransformer model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Function to fetch all hyperlinks from the main website\n",
        "def fetch_hyperlinks(base_url):\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        response = requests.get(base_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        links = [urljoin(base_url, a['href']) for a in soup.find_all('a', href=True)]\n",
        "        return list(set(links))  # Remove duplicates\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching hyperlinks: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to scrape content from a URL\n",
        "def scrape_content(url):\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        content = []\n",
        "\n",
        "        # Extract headers and paragraphs\n",
        "        for header in soup.find_all(['h1', 'h2', 'h3']):\n",
        "            section_content = f\"Header: {header.text.strip()}\"\n",
        "            paragraphs = [p.text.strip() for p in header.find_next_siblings('p')]\n",
        "            section_content += \"\\n\".join(paragraphs)\n",
        "            content.append(section_content)\n",
        "\n",
        "        return content\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping content from {url}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to find the most relevant content\n",
        "def find_relevant_content(question, content):\n",
        "    question_embedding = model.encode([question])\n",
        "    content_embeddings = model.encode(content)\n",
        "    similarities = cosine_similarity(question_embedding, content_embeddings)\n",
        "\n",
        "    # Sort content by relevance\n",
        "    sorted_indices = np.argsort(similarities[0])[::-1]\n",
        "    top_indices = sorted_indices[:3]  # Get top 3 relevant sections\n",
        "    relevant_content = [content[i] for i in top_indices]\n",
        "    return relevant_content\n",
        "\n",
        "# Main function to scrape a website and answer a question\n",
        "def main():\n",
        "    # Define websites\n",
        "    websites = {\n",
        "        '1': 'https://segment.com/docs/?ref=nav',\n",
        "        '2': 'https://docs.mparticle.com/',\n",
        "        '3': 'https://docs.lytics.com/',\n",
        "        '4': 'https://docs.zeotap.com/home/en-us/'\n",
        "    }\n",
        "\n",
        "    print(\"Please select a website from the following options:\")\n",
        "    print(\"1. Segment Documentation\")\n",
        "    print(\"2. mParticle Documentation\")\n",
        "    print(\"3. Lytics Documentation\")\n",
        "    print(\"4. Zeotap Documentation\")\n",
        "\n",
        "    choice = input(\"Enter the number corresponding to the website you want to query: \")\n",
        "    base_url = websites.get(choice)\n",
        "\n",
        "    if not base_url:\n",
        "        print(\"Invalid choice. Please try again.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nFetching content from {base_url}...\")\n",
        "\n",
        "    # Fetch hyperlinks from the base URL\n",
        "    links = fetch_hyperlinks(base_url)\n",
        "\n",
        "    if not links:\n",
        "        print(\"No hyperlinks found. Exiting.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nFound {len(links)} hyperlinks. Scraping content...\")\n",
        "\n",
        "    # Scrape content from the base URL and all sub-links\n",
        "    all_content = []\n",
        "    for link in links[:20]:  # Limit to the first 20 links for efficiency\n",
        "        all_content.extend(scrape_content(link))\n",
        "\n",
        "    print(f\"\\nScraped {len(all_content)} sections of content.\")\n",
        "\n",
        "    # Ask the user a question\n",
        "    question = input(\"\\nEnter your question: \")\n",
        "\n",
        "    # Find the most relevant content\n",
        "    relevant_content = find_relevant_content(question, all_content)\n",
        "\n",
        "    # Format and display the response\n",
        "    print(\"\\n### Answer:\")\n",
        "    for i, section in enumerate(relevant_content, 1):\n",
        "        print(f\"{i}. {section.split('Header: ')[-1].strip()}\")\n",
        "        print()\n",
        "\n",
        "    # Suggest the main link for further exploration\n",
        "    print(f\"To explore more, visit: {base_url}\")\n",
        "\n",
        "# Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "C_5_Z2eqa1zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64721078-243d-4b99-ba52-a4d210384d4f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select a website from the following options:\n",
            "1. Segment Documentation\n",
            "2. mParticle Documentation\n",
            "3. Lytics Documentation\n",
            "4. Zeotap Documentation\n",
            "Enter the number corresponding to the website you want to query: 3\n",
            "\n",
            "Fetching content from https://docs.lytics.com/...\n",
            "\n",
            "Found 37 hyperlinks. Scraping content...\n",
            "\n",
            "Scraped 379 sections of content.\n",
            "\n",
            "Enter your question: How do I build an audience segment in Lytics\n",
            "\n",
            "### Answer:\n",
            "1. Compositional InsightsCompositional Insights help you understand the makeup of your audiences. This information can answer, “what makes an audience unique?” and “How should I target these users differently?”\n",
            "Compositional Insights make it easier for you to create effective segmentation strategies. They compare data fields within audiences to surface which attributes drive user behavior. Compositional Insights currently include the following:\n",
            "This Insight compares high-value audiences on their levels of engagement. This can take the form of comparing Lytic's out-of-the-box audiences on a particular behavioral score or a custom audience.\n",
            "\n",
            "As a bite-size piece of information, this Insight Card has provided:\n",
            "This Insight compares the prevalence of specific data fields within two audiences. Candidates included are fields used in audience definitions and fields from the Promoted Schema Fields in your Account Settings.\n",
            "\n",
            "Having a granular understanding of your audiences allows you to make more strategic targeting decisions. For example, there may be a data field that your organization is paying to collect. If you discover through an Insight Card that this field is not performing as expected in your campaigns, you could save marketing spend by eliminating that field and using others that are shown to be more predictive of user behavior.\n",
            "Experience Insights help you track and understand campaign performance. This information can answer, “Which campaigns are resonating with my users?” and “Are my marketing tactics driving engagement or conversions?”\n",
            "Experience Insights allow you to refine campaigns based on current metrics proactively. Since Lytics Insights are generated and refreshed every week, you can take action to improve a campaign while it’s running.\n",
            "Experience Insights include the following types:\n",
            "This Insight will surface when an experience is missing UTM parameters, which enable Lytics to track conversions from downstream tools such as Facebook.\n",
            "\n",
            "While this Insight is more straightforward than the other types Lytics offers, it helps you quickly identify when an Experience configuration is incomplete, affecting your ability to track performance and target users who have previously engaged in future campaigns.\n",
            "This Insight appears when a significant spike up or down in campaign performance exists. Awareness of such incidents allows you to make the necessary changes to improve campaign ROI.\n",
            "For example, if conversion rates have rapidly declined for a particular campaign in the last week, you may need to reevaluate and consider changes such as refining your audience, messaging, or campaign tactics.\n",
            "Taking action based on your Insights is the most important part of the process. As the introduction explains, Lytics Insights are designed to be actionable. By understanding how users interact with your brand at a granular level, you can iterate campaigns to improve their performance and deliver better user experiences.\n",
            "User engagement is a crucial component of personalization. Each Lytics Score (quantity, frequency, recency, intensity, momentum, propensity) indicates a different aspect of user behavior,  but overall, higher scores indicate high engagement, while lower scores indicate low engagement.\n",
            "Below are some everyday use cases you might consider, depending on whether the target audience has higher behavioral scores (anything above 50) or lower behavioral scores (anything below 50).\n",
            "There are two main approaches to reaching unengaged users. The first is to drive engagement using a variety of tactics, such as messaging on different channels, targeting based on content affinities, etc. The second approach is to increase marketing efficiency by suppressing these users, thus improving your conversions.\n",
            "When creating strategies around your most active users, you will want to keep them engaged by delivering relevant content and establishing a first-party relationship that increases their Lifetime Value (LTV). You can find more users who are similar to your best customers using lookalike audiences.\n",
            "You can also learn more about what makes these engaged users different, which can inform your overall targeting strategies.\n",
            "Giving your users more of what they love is a great tactic to consider to either drive engagement for less active users or to keep currently active users engaged.\n",
            "\n",
            "2. Connect Experiences with Lytics audiencesOnce you start monitoring external Experiences, you can activate them by adding a Lytics audience. This lets you enrich your existing campaigns with Lytics behavioral audiences, content affinities, and delivery optimization.\n",
            "An example use case is to conserve Facebook ad spend by only targeting “Currently Engaged” users who have a high affinity for the content of a particular campaign. Leveraging data science under the hood, Lytics audiences can bring immediate value to your existing marketing campaigns.\n",
            "If you have already imported an external Experience, you can activate it from the Experience summary view by clicking Edit in the top right.\n",
            "\n",
            "If you want to activate an Experience that you haven't imported yet, follow the single import steps below, which will guide you through the Experience editor.\n",
            "To activate an Experience that you haven't imported yet, you will follow the workflow of creating a new Experience in Lytics. From the Experiences list view, click Add Experiences > New.\n",
            "Select your chosen provider and then Import the campaign, ad set, or journey. This example will continue with importing a SendGrid campaign.\n",
            "\n",
            "Next you will select an Authorization for your chosen provider as described above.\n",
            "\n",
            "Then you will select the campaign or ad set to import. Note that here you can only import one Experience at a time. Click Import 1 Experience to continue.\n",
            "Finally, you will complete the following Experience Editor steps:\n",
            "Upon completion, your Experience will be ready to publish.\n",
            "\n",
            "3. Audience PairsThis Insight compares high-value audiences on their levels of engagement. This can take the form of comparing Lytic's out-of-the-box audiences on a particular behavioral score or a custom audience.\n",
            "\n",
            "As a bite-size piece of information, this Insight Card has provided:\n",
            "This Insight compares the prevalence of specific data fields within two audiences. Candidates included are fields used in audience definitions and fields from the Promoted Schema Fields in your Account Settings.\n",
            "\n",
            "Having a granular understanding of your audiences allows you to make more strategic targeting decisions. For example, there may be a data field that your organization is paying to collect. If you discover through an Insight Card that this field is not performing as expected in your campaigns, you could save marketing spend by eliminating that field and using others that are shown to be more predictive of user behavior.\n",
            "Experience Insights help you track and understand campaign performance. This information can answer, “Which campaigns are resonating with my users?” and “Are my marketing tactics driving engagement or conversions?”\n",
            "Experience Insights allow you to refine campaigns based on current metrics proactively. Since Lytics Insights are generated and refreshed every week, you can take action to improve a campaign while it’s running.\n",
            "Experience Insights include the following types:\n",
            "This Insight will surface when an experience is missing UTM parameters, which enable Lytics to track conversions from downstream tools such as Facebook.\n",
            "\n",
            "While this Insight is more straightforward than the other types Lytics offers, it helps you quickly identify when an Experience configuration is incomplete, affecting your ability to track performance and target users who have previously engaged in future campaigns.\n",
            "This Insight appears when a significant spike up or down in campaign performance exists. Awareness of such incidents allows you to make the necessary changes to improve campaign ROI.\n",
            "For example, if conversion rates have rapidly declined for a particular campaign in the last week, you may need to reevaluate and consider changes such as refining your audience, messaging, or campaign tactics.\n",
            "Taking action based on your Insights is the most important part of the process. As the introduction explains, Lytics Insights are designed to be actionable. By understanding how users interact with your brand at a granular level, you can iterate campaigns to improve their performance and deliver better user experiences.\n",
            "User engagement is a crucial component of personalization. Each Lytics Score (quantity, frequency, recency, intensity, momentum, propensity) indicates a different aspect of user behavior,  but overall, higher scores indicate high engagement, while lower scores indicate low engagement.\n",
            "Below are some everyday use cases you might consider, depending on whether the target audience has higher behavioral scores (anything above 50) or lower behavioral scores (anything below 50).\n",
            "There are two main approaches to reaching unengaged users. The first is to drive engagement using a variety of tactics, such as messaging on different channels, targeting based on content affinities, etc. The second approach is to increase marketing efficiency by suppressing these users, thus improving your conversions.\n",
            "When creating strategies around your most active users, you will want to keep them engaged by delivering relevant content and establishing a first-party relationship that increases their Lifetime Value (LTV). You can find more users who are similar to your best customers using lookalike audiences.\n",
            "You can also learn more about what makes these engaged users different, which can inform your overall targeting strategies.\n",
            "Giving your users more of what they love is a great tactic to consider to either drive engagement for less active users or to keep currently active users engaged.\n",
            "\n",
            "To explore more, visit: https://docs.lytics.com/\n"
          ]
        }
      ]
    }
  ]
}